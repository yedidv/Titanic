{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yedidv/Titanic/blob/master/hw5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sVgU84dbDxJ"
      },
      "source": [
        "## Homework 05 - Instructions\n",
        "\n",
        "![](https://github.com/rpi-techfundamentals/hm-01-starter/blob/master/notsaved.png?raw=1)\n",
        "\n",
        "**WARNING!!!  If you see this icon on the top of your COLAB sesssion, your work is not saved automatically.**\n",
        "\n",
        "\n",
        "**When you are working on homeworks, make sure that you save often. You may find it easier to save intermident copies in Google drive. If you save your working file in Google drive all changes will be saved as you work. MAKE SURE that your final version is saved to GitHub.** \n",
        "\n",
        "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All).  You can speak with others regarding the assignment but all work must be your own. \n",
        "\n",
        "\n",
        "### This is a 30 point assignment graded from answers to questions and automated tests that should be run at the bottom. Be sure to clearly label all of your answers and commit final tests at the end.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v3MgKRzlHu2",
        "outputId": "e9716dbc-bf49-43cb-9c50-fe30b329bada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "files = \"https://github.com/rpi-techfundamentals/introml_website_fall_2020/raw/master/files/assignment5.zip\" \n",
        "!pip install otter-grader && wget $files && unzip -o assignment5.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting otter-grader\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/a1/7fa40af4cdeb924ca691716032f4d161c927600523c821f7b46d1cb9b51f/otter_grader-1.1.3-py3-none-any.whl (169kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from otter-grader) (5.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from otter-grader) (1.1.2)\n",
            "Requirement already satisfied: nbconvert<6.0.0 in /usr/local/lib/python3.6/dist-packages (from otter-grader) (5.6.1)\n",
            "Collecting pdfkit\n",
            "  Downloading https://files.pythonhosted.org/packages/57/da/48fdd627794cde49f4ee7854d219f3a65714069b722b8d0e3599cd066185/pdfkit-0.6.1-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from otter-grader) (4.41.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from otter-grader) (5.1.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from otter-grader) (3.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from otter-grader) (2.11.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from otter-grader) (5.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from otter-grader) (50.3.0)\n",
            "Collecting PyPDF2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from otter-grader) (0.3.2)\n",
            "Collecting docker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/8c/8d42dbd83679483db207535f4fb02dc84325fa78b290f057694b057fcd21/docker-4.3.1-py2.py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->otter-grader) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->otter-grader) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->otter-grader) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->otter-grader) (4.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->otter-grader) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->otter-grader) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->otter-grader) (1.0.18)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->otter-grader) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->otter-grader) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->otter-grader) (2.8.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert<6.0.0->otter-grader) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<6.0.0->otter-grader) (1.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<6.0.0->otter-grader) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert<6.0.0->otter-grader) (3.2.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert<6.0.0->otter-grader) (0.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert<6.0.0->otter-grader) (4.6.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert<6.0.0->otter-grader) (0.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->otter-grader) (1.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->otter-grader) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->otter-grader) (2.6.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from docker->otter-grader) (1.15.0)\n",
            "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /usr/local/lib/python3.6/dist-packages (from docker->otter-grader) (2.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->otter-grader) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->otter-grader) (0.2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert<6.0.0->otter-grader) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert<6.0.0->otter-grader) (20.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests!=2.18.0,>=2.14.2->docker->otter-grader) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests!=2.18.0,>=2.14.2->docker->otter-grader) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests!=2.18.0,>=2.14.2->docker->otter-grader) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests!=2.18.0,>=2.14.2->docker->otter-grader) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert<6.0.0->otter-grader) (2.4.7)\n",
            "Building wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-cp36-none-any.whl size=61086 sha256=2707667a16a883bebe51102141368f2f86cfb4064c6d45e36c060f5e8f5d14c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: pdfkit, PyPDF2, websocket-client, docker, otter-grader\n",
            "Successfully installed PyPDF2-1.26.0 docker-4.3.1 otter-grader-1.1.3 pdfkit-0.6.1 websocket-client-0.57.0\n",
            "--2020-10-08 21:39:57--  https://github.com/rpi-techfundamentals/introml_website_fall_2020/raw/master/files/assignment5.zip\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rpi-techfundamentals/introml_website_fall_2020/master/files/assignment5.zip [following]\n",
            "--2020-10-08 21:39:58--  https://raw.githubusercontent.com/rpi-techfundamentals/introml_website_fall_2020/master/files/assignment5.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49011 (48K) [application/zip]\n",
            "Saving to: ‘assignment5.zip’\n",
            "\n",
            "assignment5.zip     100%[===================>]  47.86K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-10-08 21:39:58 (1.89 MB/s) - ‘assignment5.zip’ saved [49011/49011]\n",
            "\n",
            "Archive:  assignment5.zip\n",
            "  inflating: test-new.csv            \n",
            "   creating: tests/\n",
            "  inflating: tests/q01.py            \n",
            "  inflating: tests/q05.py            \n",
            "  inflating: tests/__init__.py       \n",
            "  inflating: tests/q03.py            \n",
            "  inflating: tests/q02.py            \n",
            "  inflating: tests/q06.py            \n",
            "   creating: tests/.ipynb_checkpoints/\n",
            "  inflating: train-new.csv           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W1-ZeqRbDxX"
      },
      "source": [
        "#Run this. It initiates autograding. \n",
        "import otter\n",
        "grader = otter.Notebook()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y19n7hxbDxf"
      },
      "source": [
        "### Load Data\n",
        "We have our titanic dataset that is a bit different from what we have had previously. Load the train-new.csv and test-new.csv into dataframes train and test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQAhByH7bDxh",
        "outputId": "e0f6d235-7d17-4872-a8ff-7c2501f1b3df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "# Load the data here\n",
        "import pandas as pd \n",
        "train = pd.read_csv('train-new.csv') \n",
        "X_test = pd.read_csv('test-new.csv') \n",
        "\n",
        "train.head() \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Title</th>\n",
              "      <th>family_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>H</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>H</td>\n",
              "      <td>S</td>\n",
              "      <td>Miss</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C</td>\n",
              "      <td>S</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>H</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ... Embarked Title  family_size\n",
              "0            1         0       3  ...        S    Mr            2\n",
              "1            2         1       1  ...        C   Mrs            2\n",
              "2            3         1       3  ...        S  Miss            1\n",
              "3            4         1       1  ...        S   Mrs            2\n",
              "4            5         0       3  ...        S    Mr            1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tct7SvxbDxk"
      },
      "source": [
        "## Question 1\n",
        "(1) Investigate the data a little bit. What is different from some of the titanic datasets we have used in the past? (For example, compare against the data in the Kaggle Baseline notebook). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6NbB3webDxk"
      },
      "source": [
        "man1=\"\"\"\n",
        "\n",
        "These data sets seem to be very similar. \n",
        "The only noticable difference was the kaggle \n",
        "dataset did not have the title of the passenger, \n",
        "nor did it have the size of the family. \n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvdymnRqbDxs"
      },
      "source": [
        "# Generating Dummy Variables\n",
        "Before we do analysis of the titanic dataset, we have to select out our features, for the train and the test set, which we shall label `X_train`, and `X_test`.\n",
        "\n",
        "As a part of this we need to generate `n-1` dummy variables for each one of our categorical columns.  The resulting dataframes should be all numeric and have all of these columns below (in the correct order).\n",
        "\n",
        "Follow the example above to generate a new value for `X_train` and `X_test` utilizing all the data.\n",
        "```\n",
        "['Age', 'SibSp', 'Parch', 'Fare', 'family_size', 'Pclass_2', 'Pclass_3', 'Sex_male', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_H', 'Embarked_Q', 'Embarked_S']\n",
        "\n",
        "```\n",
        "*Hint, try: \n",
        "`help(pd.get_dummies)`* \n",
        "\n",
        "You should also set `y` to the Survived column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRMRcW92bDxt",
        "outputId": "5c1f5874-58f6-4d50-c19b-10fdff51be85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "#Answer Here \n",
        "\n",
        "y = train['Survived']\n",
        "def NarrowX(x): \n",
        "  x = pd.get_dummies(\n",
        "      x, columns =['Pclass', 'Sex', 'Cabin', 'Embarked']) \n",
        "  narrow_x = x[['Age', 'SibSp',  'Parch', 'Fare', \n",
        "                                  'family_size', \n",
        "                                  'Pclass_2', \n",
        "                                  'Pclass_3', \n",
        "                                  'Sex_male', \n",
        "                                  'Cabin_B', \n",
        "                                  'Cabin_C', \n",
        "                                  'Cabin_D', \n",
        "                                  'Cabin_E', \n",
        "                                  'Cabin_F', \n",
        "                                  'Cabin_G', \n",
        "                                  'Cabin_H',\n",
        "                                  'Embarked_Q', \n",
        "                                  'Embarked_S']]\n",
        "  return narrow_x\n",
        "X_train = NarrowX(train) \n",
        "X_test = NarrowX(X_test) \n",
        "\n",
        "\n",
        "X_train.columns.values.tolist()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Age',\n",
              " 'SibSp',\n",
              " 'Parch',\n",
              " 'Fare',\n",
              " 'family_size',\n",
              " 'Pclass_2',\n",
              " 'Pclass_3',\n",
              " 'Sex_male',\n",
              " 'Cabin_B',\n",
              " 'Cabin_C',\n",
              " 'Cabin_D',\n",
              " 'Cabin_E',\n",
              " 'Cabin_F',\n",
              " 'Cabin_G',\n",
              " 'Cabin_H',\n",
              " 'Embarked_Q',\n",
              " 'Embarked_S']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd3uMB5jbDxw",
        "outputId": "b408e966-6c81-4cc4-953e-55db4a658fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "grader.check('q01')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uYEpxPJbDxy"
      },
      "source": [
        "## Split Training Set For Cross Validation\n",
        "(2.) We want to split up our training set `X` so that we can do some cross validation. Specifically, we will start to use the term validation set for the set we will use to validate our model. \n",
        "\n",
        "In doing so below, use the sklearn methods to do a train test (i.e., validation) split.  \n",
        "\n",
        "From X y dataframe, generate the following dataframes by drawing the data **randomly**  from the train dataframe 80% of the data in train and 20% of the data in test.  So that you get repeatable results, set the `random_state=100`. This will set a \"seed\" so that your random selection will be the same as mine and you will pass the internal tests. \n",
        "\n",
        "train_X, val_X, train_y, val_y\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkM_vc03bDx0",
        "outputId": "749d5771-e952-4b5e-9be6-f08eaec6ad33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Answer Here\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "train_X, val_X, train_y, val_y = train_test_split(X_train, y, train_size = 0.8, \n",
        "                                                    test_size = 0.2, \n",
        "                                                    random_state = 100)\n",
        "\n",
        "int(val_y.sum())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm-IdaQBbDx2",
        "outputId": "029c48e6-8ca7-463d-c91b-ad0df37aa92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "grader.check('q02')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OfjwSA_bDx4"
      },
      "source": [
        "### Perform Nearest Neighbor Classification (KNeighborsClassifier)\n",
        "(3.) Using the default options (i.e., all default hyperparameters), perform nearest neighbor classification. Calculate the accuracy measure using `metrics.accuracy_score`.\n",
        "\n",
        "Train your model using the training data and access the accuracy of both the training and validation data.\n",
        "\n",
        "*Note: You only train the model once...on the training data. You then assess the performance on both the training and validation data.*\n",
        "\n",
        "Assign the following variables:\n",
        "\n",
        "`knn0_train_y` = The KNN prediction for the `train_X` data. \n",
        "\n",
        "`knn0_val_y`   = The KNN prediction for the `val_X` data. \n",
        "\n",
        "`knn0_train_accuracy` = The accuracy for the `knn0_train_y` prediction. \n",
        "\n",
        "`knn0_val_accuracy` = The accuracy for the `knn0_val_y` prediction. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaM1D9X8bDx4",
        "outputId": "023bac16-4b0a-4691-cdbc-35a538580099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Answer Here \n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "\n",
        "classifier = KNeighborsClassifier() \n",
        "\n",
        "classifier.fit(train_X, train_y)\n",
        "\n",
        "knn0_train_y = classifier.predict(train_X) \n",
        "\n",
        "knn0_val_y = classifier.predict(val_X) \n",
        "\n",
        "knn0_train_accuracy = classifier.score(train_X, train_y)\n",
        "knn0_val_accuracy = classifier.score(val_X, val_y)\n",
        "\n",
        "int(knn0_val_y.sum())\n",
        "\n",
        "round(knn0_train_accuracy, 2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2P2aGmlbDx6",
        "outputId": "07a52c3a-bac6-43f9-d035-82b80ebca89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "grader.check('q03')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkJxVYRRbDx7"
      },
      "source": [
        "### Confusion Matrix\n",
        "We can utilize a confusion matrix to be able to understand misclassifications a bit more. This will give us a full idea of the true positives, true negatives, false positives, and false negatives.  \n",
        "\n",
        "See the documentation [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). \n",
        "\n",
        "You can utilize the syntax below to generate knn_mat1_train and knn_mat1_test.  \n",
        "```\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_true, y_pred)\n",
        "```\n",
        "**(4.)  Explain what each of the four quadrants of the confusion matrix means. **\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DaWF4R1bDx8"
      },
      "source": [
        "#Answer here\n",
        "man4= \"\"\"\n",
        "\n",
        "A confusion matrix represents the different errors \n",
        "We can have true positives, where the prediction is\n",
        "said to be true when it really is (no error) on the \n",
        "top left. \n",
        "\n",
        "The top right is a false negative when we say it's \n",
        "false when it is not. \n",
        "\n",
        "the bottom right is a true negative when it's said \n",
        "to be false when it really is \n",
        "\n",
        "The bottom left is a false positive when it's said \n",
        "to be true when it really is not. \n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpeH8Vn5bDx9"
      },
      "source": [
        "### Create Confusion Matrix for the Training and Validation Predictions\n",
        "(5) Create a confusion matrix for each of the training and valiation predictions. \n",
        "`knn0_con_train` A confusion matrix for the training data.  \n",
        "`knn0_con_val` A confusion matrix for the validation data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uDyUHRgbDx-"
      },
      "source": [
        "#Answers \n",
        "from sklearn.metrics import confusion_matrix \n",
        "\n",
        "knn0_con_train = confusion_matrix(train_y, knn0_train_y) \n",
        "knn0_con_val = confusion_matrix(val_y, knn0_val_y) \n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9QESf1FbDyB",
        "outputId": "7a344fc9-bbe1-4b82-8226-adc2fdfe00c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "grader.check('q05')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZWiT21KbDyC"
      },
      "source": [
        "## Hyperparameter Tuning\n",
        "\n",
        "(6) You created a single model using the default parameters.  However, we want to adjust the parameters to try and improve the model.  \n",
        "\n",
        "Examine the documentation on KNN and see some of the different parameters that you can adjust. \n",
        "\n",
        "[Scikit Learn Documentation](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning).\n",
        "\n",
        "Assign the following variables:\n",
        "\n",
        "`knn1_train_y` = The KNN prediction for the `train_X` datafor your improved model. \n",
        "\n",
        "`knn1_val_y`   = The KNN prediction for the `val_X` data for your improved model. \n",
        "\n",
        "`knn1_train_accuracy` = The accuracy for the `knn1_train_y` prediction. \n",
        "\n",
        "`knn1_val_accuracy` = The accuracy for the `knn1_val_y` prediction. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hklt5muJbDyD",
        "outputId": "e292c9f9-5da3-4718-9204-3cb43d101f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Answers\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors = 2) \n",
        "\n",
        "classifier.fit(train_X, train_y)\n",
        "\n",
        "knn1_train_y = classifier.predict(train_X) \n",
        "\n",
        "knn1_val_y = classifier.predict(val_X) \n",
        "\n",
        "knn1_train_accuracy = classifier.score(train_X, train_y)\n",
        "\n",
        "knn1_val_accuracy = classifier.score(val_X, val_y)\n",
        "\n",
        "int(knn0_val_y.sum())\n",
        "\n",
        "round(knn1_train_accuracy, 2) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr2TPzBPbDyE",
        "outputId": "80d672ba-45a2-48d1-b277-d3e130ecfd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "grader.check('q06')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qiZ8IlkbDyF"
      },
      "source": [
        "### Other Models\n",
        "\n",
        "(7.) Test Logistic regression and 1 other algorithms/models (your choice).  Provide a summary of the best performance below. \n",
        "\n",
        "Use any of the available classification models. You should show and comment code\n",
        "\n",
        "[Scikit Learn Documentation](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning).\n",
        "\n",
        "*Make sure your clearly indicate the accuracy of the Logistic regression model your other model. Assess which model worked best considering all your efforts.*\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTrS9ymAFu1S",
        "outputId": "547f1201-72b9-45dc-abd2-9397a0b2b5d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "\n",
        "logistic = LogisticRegression() \n",
        "\n",
        "logistic.fit(train_X, train_y) \n",
        "\n",
        "knn2_train_y = logistic.predict(train_X) \n",
        "\n",
        "knn2_val_y = logistic.predict(val_X) \n",
        "\n",
        "knn2_train_accuracy = logistic.score(train_X, train_y)\n",
        "\n",
        "knn2_val_accuracy = logistic.score(val_X, val_y)\n",
        "\n",
        "int(knn2_val_y.sum())\n",
        "\n",
        "round(knn1_train_accuracy, 2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCTsUctjI2_O",
        "outputId": "da971c57-1075-4436-e70d-b8ef27a89a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans() \n",
        "\n",
        "\n",
        "logistic.fit(train_X, train_y) \n",
        "\n",
        "knn3_train_y = logistic.predict(train_X) \n",
        "\n",
        "knn3_val_y = logistic.predict(val_X) \n",
        "\n",
        "knn3_train_accuracy = logistic.score(train_X, train_y)\n",
        "\n",
        "knn3_val_accuracy = logistic.score(val_X, val_y)\n",
        "\n",
        "int(knn3_val_y.sum())\n",
        "\n",
        "round(knn3_train_accuracy, 2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtzjtrQXbDyG"
      },
      "source": [
        "#Answer here\n",
        "man7= \"\"\"\n",
        "\n",
        "The original model had an accuracy of 0.81 \n",
        "\n",
        "With some hyperparameter tuning, I was able to bring \n",
        "up the accuracy to 0.85 \n",
        "\n",
        "The logistic regression was able to get an accuracy of 0.85 \n",
        "\n",
        "The kMeans was able to give an accuracy of 0.82. \n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxSAKguCbDyI",
        "outputId": "7d440aa5-ad4c-4ace-9fd2-e37e639530a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "#This runs all tests. \n",
        "grader.check_all()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<p><strong>q01:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>q02:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>q03:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>q05:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>q06:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n"
            ],
            "text/plain": [
              "q01:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "q02:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "q03:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "q05:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "q06:\n",
              "\n",
              "    All tests passed!\n",
              "    \n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA-o9pxclHvZ"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}